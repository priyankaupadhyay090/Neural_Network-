{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Priyanka_Multilayer _Perceptron.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7oFhmWejmjR"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfmoXJzyjGWu"
      },
      "source": [
        "# Multi-Task Learning and Data Augmentation\n",
        "\n",
        "### Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asEbG0uujpYO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGEHpGzDjuLN"
      },
      "source": [
        "## # -*- coding: utf-8 -*-\r\n",
        "## multilayer_perceptron.ipynb\r\n",
        "\r\n",
        "### A Multilayer Perceptron implementation example using Pytorch.\r\n",
        "### This example does handwritten digit recognition using the MNIST database.\r\n",
        "#### (http://yann.lecun.com/exdb/mnist/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5klYK9PjscV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhq9UBQbjGW7"
      },
      "source": [
        "\n",
        "## necessary packages \n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01pNt6LnjGW-"
      },
      "source": [
        "#### Network hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf958cVnjGW_"
      },
      "source": [
        "\n",
        "input_size = 28*28\n",
        "hidden_layer_size= 512\n",
        "output_size = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 1e-3\n",
        "learning_rate_decay = 0.8\n",
        "num_workers = 0"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wpK9obDjGW_"
      },
      "source": [
        "#### Load MNIST train and test datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T70Pb4nLjGXA"
      },
      "source": [
        "\n",
        "def load_dataset():\n",
        "    train_data = datasets.MNIST(root='data', train=True,\n",
        "                                   download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.MNIST(root='data', train=False,\n",
        "                                  download=True, transform=transforms.ToTensor())\n",
        "    \n",
        "    test_size = len(test_data)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "    ## Transform data with padding 1\n",
        "    data_transform  = transforms.Compose([transforms.ToTensor(),transforms.Pad(1)])\n",
        "    \n",
        "    ## Normalizing the datasets\n",
        "    normalized_data = datasets.MNIST(root='data', train=True,\n",
        "                                  download=True, transform=data_transform)\n",
        "   \n",
        "    normalized = torch.utils.data.DataLoader(normalized_data, batch_size=batch_size, \n",
        "                                             num_workers=num_workers)\n",
        "\n",
        "\n",
        "    return train_loader,test_loader,test_size,  normalized\n",
        "\n",
        "\n",
        "train_loader,test_loader,test_size, n_train_loader = load_dataset()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCZLhbqrjGXB"
      },
      "source": [
        "#### function to update learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEoBaCwtjGXB"
      },
      "source": [
        "\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pydHgD_IjGXC"
      },
      "source": [
        "#### Create model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMm-FLoFjGXC"
      },
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        # Input layer\n",
        "        self.fc1 = nn.Linear(input_size, hidden_layer_size)\n",
        "        \n",
        "        # Hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc3 = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, input_size)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wh9euRvkpuS",
        "outputId": "379395b1-5446-4c94-8d02-0f7b88891ffc"
      },
      "source": [
        "# Initialize model\r\n",
        "model = MLP()\r\n",
        "print(model)\r\n",
        "\r\n",
        "\r\n",
        "# Specify loss function\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Specify optimizer\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8edjuW17jGXC"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbh4ovJSjGXD",
        "outputId": "d6306ce1-b133-4efc-afd3-ec497db85edc"
      },
      "source": [
        "\n",
        "model.train()\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Loading each input batch\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Outputs after forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "         # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backprop to update model parameters \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Update learning rate for next epoch       \n",
        "    learning_rate *= learning_rate_decay\n",
        "    update_lr(optimizer, learning_rate)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [50/600], Loss: 2.3053\n",
            "Epoch [1/2], Step [100/600], Loss: 2.3045\n",
            "Epoch [1/2], Step [150/600], Loss: 2.2985\n",
            "Epoch [1/2], Step [200/600], Loss: 2.3082\n",
            "Epoch [1/2], Step [250/600], Loss: 2.2946\n",
            "Epoch [1/2], Step [300/600], Loss: 2.2975\n",
            "Epoch [1/2], Step [350/600], Loss: 2.2941\n",
            "Epoch [1/2], Step [400/600], Loss: 2.2901\n",
            "Epoch [1/2], Step [450/600], Loss: 2.2880\n",
            "Epoch [1/2], Step [500/600], Loss: 2.2934\n",
            "Epoch [1/2], Step [550/600], Loss: 2.2875\n",
            "Epoch [1/2], Step [600/600], Loss: 2.2825\n",
            "Epoch [2/2], Step [50/600], Loss: 2.2775\n",
            "Epoch [2/2], Step [100/600], Loss: 2.2752\n",
            "Epoch [2/2], Step [150/600], Loss: 2.2734\n",
            "Epoch [2/2], Step [200/600], Loss: 2.2848\n",
            "Epoch [2/2], Step [250/600], Loss: 2.2729\n",
            "Epoch [2/2], Step [300/600], Loss: 2.2787\n",
            "Epoch [2/2], Step [350/600], Loss: 2.2714\n",
            "Epoch [2/2], Step [400/600], Loss: 2.2684\n",
            "Epoch [2/2], Step [450/600], Loss: 2.2658\n",
            "Epoch [2/2], Step [500/600], Loss: 2.2716\n",
            "Epoch [2/2], Step [550/600], Loss: 2.2663\n",
            "Epoch [2/2], Step [600/600], Loss: 2.2640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8rCsaHMjGXH"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRhQRBxDjGXH",
        "outputId": "210aa329-61e5-4f03-ea69-0f12116d333f"
      },
      "source": [
        "# Test\n",
        "model.eval()\n",
        "correct=0\n",
        "for images, labels in test_loader:\n",
        "\n",
        "    # Compute predicted outputs (forward pass)\n",
        "    output = model(images)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    # Convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    # compare predictions to true labels\n",
        "    correct += (pred == labels).sum().item()\n",
        "    \n",
        "\n",
        "# Test accuracy\n",
        "print('Accuracy of the MLP on {} test images: {} %'.format(test_size, 100 * (correct / test_size)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the MLP on 10000 test images: 45.540000000000006 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_u3QuXPojE9"
      },
      "source": [
        "## Shifiting image in all four directions\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aisleV5Cop4P"
      },
      "source": [
        ""
      ]
    }
  ]
}